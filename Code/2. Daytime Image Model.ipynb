{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_Daytime Image Model.ipynb","provenance":[],"authorship_tag":"ABX9TyMnLtQfDn+SL8sNOY8FAik7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bR7TxHM4SHmw","colab_type":"code","colab":{}},"source":["import time\n","import os\n","import os.path\n","from osgeo import gdal, ogr, osr\n","from scipy import ndimage\n","from scipy import misc\n","from io import StringIO\n","gdal.UseExceptions()\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from matplotlib import gridspec\n","%matplotlib inline\n","import urllib\n","import pandas as pd\n","import numpy as np "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OfWJiKrESbp_","colab_type":"code","outputId":"d009bd80-92d8-46c6-c2d6-cc5054e20e16","executionInfo":{"status":"ok","timestamp":1585723466610,"user_tz":-120,"elapsed":2028,"user":{"displayName":"Huy Dang","photoUrl":"","userId":"10454985520596324333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nn2ij8u3SfQx","colab_type":"code","outputId":"5040c76e-7b84-4580-95bb-c35727db6e1d","executionInfo":{"status":"ok","timestamp":1585723474323,"user_tz":-120,"elapsed":7623,"user":{"displayName":"Huy Dang","photoUrl":"","userId":"10454985520596324333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.applications.vgg16 import VGG16\n","import numpy as np\n","from keras.preprocessing import image\n","from keras.models import Sequential\n","from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n","from keras.layers.convolutional import Convolution2D, AveragePooling2D\n","from keras.optimizers import SGD\n","from keras.layers.core import Activation\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dense\n","from keras.layers import Dropout\n","from multiprocessing import Pool\n","import os\n","import time\n","import pandas as pd\n","import numpy as np\n","from keras.models import Model\n","import pickle \n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qSASe6H9Sj8B","colab_type":"code","outputId":"3ad34d44-c341-4619-dcc8-62f5f844b810","executionInfo":{"status":"ok","timestamp":1585723501306,"user_tz":-120,"elapsed":25340,"user":{"displayName":"Huy Dang","photoUrl":"","userId":"10454985520596324333"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["#Mount GDrive to access satellite images data\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZMnOmNAwSlkN","colab_type":"code","outputId":"512fe6be-6028-4c5b-d933-ec05226750fc","executionInfo":{"status":"error","timestamp":1585723539957,"user_tz":-120,"elapsed":6277,"user":{"displayName":"Huy Dang","photoUrl":"","userId":"10454985520596324333"}},"colab":{"base_uri":"https://localhost:8080/","height":181}},"source":["#load images file names dictionary\n","with open('/content/drive/My Drive/Thesis/daytime_analysis/images_name_dict', 'rb') as fp:\n","    images_name_dict = pickle.load(fp)"],"execution_count":6,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-14838932ddea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Thesis/daytime_analysis/images_name_dict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimages_name_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"]}]},{"cell_type":"code","metadata":{"id":"_ZWVnYUuTuwh","colab_type":"code","colab":{}},"source":["#Make directory for unloading satellite images\n","os.mkdir('/content/google_images')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBl_rZPbYK-a","colab_type":"code","outputId":"77520f5d-b1d4-4187-95ad-c98cd5e4670b","executionInfo":{"status":"ok","timestamp":1585723551612,"user_tz":-120,"elapsed":3698,"user":{"displayName":"Huy Dang","photoUrl":"","userId":"10454985520596324333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Copy satellite files from Drive and unload into local directory of Colab\n","#os.chdir('/content/drive/My Drive/Thesis/')\n","!cp /content/drive/My\\ Drive/Thesis/google_images.zip /content/google_images"],"execution_count":7,"outputs":[{"output_type":"stream","text":["cp: error reading '/content/drive/My Drive/Thesis/google_images.zip': Operation canceled\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pzMGVxHRTBFL","colab_type":"code","outputId":"bf55cb46-5958-43a5-b8c0-fc770681861e","executionInfo":{"status":"ok","timestamp":1585721306172,"user_tz":-120,"elapsed":180898,"user":{"displayName":"Huy Dang","photoUrl":"","userId":"10454985520596324333"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Copy satellite files from Drive and unload into local directory of Colab\n","os.chdir('/content/google_images') "],"execution_count":0,"outputs":[{"output_type":"stream","text":["cp: error reading '/content/drive/My Drive/Thesis/google_images.zip': Operation canceled\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9rgiMy8NV0hS","colab_type":"code","outputId":"cb9114dc-766d-45cb-de77-29df4320825a","executionInfo":{"status":"ok","timestamp":1585721108654,"user_tz":-120,"elapsed":5496,"user":{"displayName":"Huy Dang","photoUrl":"","userId":"10454985520596324333"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!unzip -qq google_images.zip"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[google_images.zip]\n","  End-of-central-directory signature not found.  Either this file is not\n","  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n","  latter case the central directory and zipfile comment will be found on\n","  the last disk(s) of this archive.\n","unzip:  cannot find zipfile directory in one of google_images.zip or\n","        google_images.zip.zip, and cannot find google_images.zip.ZIP, period.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7coCPtvHT8Y5","colab_type":"code","colab":{}},"source":["#Move satellite images data to folders according to their lightness intensity\n","\n","import sys, string, os, shutil\n","\n","def move_to_group(lightness_small, lightness_big, class_id):\n","    new_directory = 'data/google_image_cnn/class_' + str(class_id) + '/'\n","    if not os.path.isdir(new_directory):\n","        os.makedirs(new_directory)\n","    for i in range(lightness_small, lightness_big):\n","        path = '/content/google_images/google_images/' + str(i) + '/'\n","        for f in os.listdir(path):\n","            shutil.copyfile(path + f, new_directory + f)\n","\n","move_to_group(0, 1, 1)\n","move_to_group(4, 35, 2)\n","move_to_group(35, 64, 3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"amEnn4EyUbCA","colab_type":"code","colab":{}},"source":["#Create Training and Test Set \n","\n","import os\n","import numpy as np\n","import shutil\n","import random\n","\n","# # Creating Train / Val / Test folders (One time use)\n","root_dir = '/content/google_images/data/google_image_cnn/'\n","classes_dir = ['class_1', 'class_2', 'class_3']\n","\n","#val_ratio = 0.15\n","test_ratio = 0.3\n","\n","for cls in classes_dir:\n","    os.makedirs(root_dir +'train/' + cls)\n","    #os.makedirs(root_dir +'/val' + cls)\n","    os.makedirs(root_dir +'test/' + cls)\n","\n","\n","    # Creating partitions of the data after shuffling\n","    src = root_dir + cls # Folder to copy images from\n","\n","    allFileNames = os.listdir(src)\n","    np.random.shuffle(allFileNames)\n","    train_FileNames, test_FileNames = np.split(np.array(allFileNames),[int(len(allFileNames)* (1 - test_ratio))])\n","\n","\n","    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n","    #val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]\n","    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n","\n","    print('Total images: ', len(allFileNames))\n","    print('Training: ', len(train_FileNames))\n","    #print('Validation: ', len(val_FileNames))\n","    print('Testing: ', len(test_FileNames))\n","\n","    # Copy-pasting images\n","    for name in train_FileNames:\n","        shutil.copy(name, root_dir +'train/' + cls)\n","\n","    #for name in val_FileNames:\n","        #shutil.copy(name, root_dir +'/val' + cls)\n","\n","    for name in test_FileNames:\n","        shutil.copy(name, root_dir +'test/' + cls)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4XPqhXnUpgh","colab_type":"code","colab":{}},"source":["# get image features\n","\n","model_old = VGG16(weights='imagenet', include_top=False)\n","\n","\n","def get_input_feature(img_path):\n","    # img = image.load_img(img_path, target_size=(400, 400))\n","    img = image.load_img(img_path)\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    features = model_old.predict(x)\n","    return features[0]\n","\n","\n","# train\n","all_figures = []\n","trainLabels = []\n","\n","# need upsampling because of the unbalance of the training classes\n","path_1 = '/content/google_images/data/google_image_cnn/train/class_1/'\n","# path_1 = 'google_image_cnn/class_1/'\n","class_1_files = os.listdir(path_1)\n","trainLabels += [[1, 0, 0]] * len(class_1_files)\n","all_figures += [path_1 + i for i in class_1_files]\n","\n","path_2 = '/content/google_images/data/google_image_cnn/train/class_2/'\n","# path_2 = 'google_image_cnn/class_2/'\n","class_2_files = os.listdir(path_2)\n","trainLabels += [[0, 1, 0]] * len(class_2_files)\n","all_figures += [path_2 + i for i in class_2_files]\n","\n","path_3 = '/content/google_images/data/google_image_cnn/train/class_1/'\n","# path_3 = 'google_image_cnn/class_3/'\n","class_3_files = os.listdir(path_3)\n","trainLabels += [[0, 0, 1]] * len(class_3_files)\n","all_figures += [path_3 + i for i in class_3_files]\n","\n","\n","# a = get_input_feature(all_figures[0])\n","# pool = Pool(10)\n","# trainData = pool.map(get_input_feature, all_figures)\n","\n","trainData = []\n","t1 = time.time()\n","for idx, i in enumerate(all_figures):\n","    a = get_input_feature(i)\n","    trainData.append(a)\n","    if idx % 1000 == 0:\n","        t2 = time.time()\n","        print(idx)\n","        print(t2 - t1)\n","        t1 = time.time()\n","\n","\n","x_all = np.asarray(trainData)\n","y_all = np.asarray(trainLabels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrP0ttBrVFI3","colab_type":"code","colab":{}},"source":["# test\n","all_figures = []\n","testLabels = []\n","\n","path_1 = '/content/google_images/data/google_image_cnn/test/class_1/'\n","# path_1 = 'google_image_cnn/class_1/'\n","class_1_files = os.listdir(path_1)\n","testLabels += [[1, 0, 0]] * len(class_1_files)\n","all_figures += [path_1 + i for i in class_1_files]\n","\n","path_2 = '/content/google_images/data/google_image_cnn/test/class_2/'\n","# path_2 = 'google_image_cnn/class_2/'\n","class_2_files = os.listdir(path_2)\n","testLabels += [[0, 1, 0]] * len(class_2_files)\n","all_figures += [path_2 + i for i in class_2_files]\n","\n","path_3 = '/content/google_images/data/google_image_cnn/train/class_3/'\n","# path_3 = 'google_image_cnn/class_3/'\n","class_3_files = os.listdir(path_3)\n","testLabels += [[0, 0, 1]] * len(class_3_files)\n","all_figures += [path_3 + i for i in class_3_files]\n","\n","\n","# a = get_input_feature(all_figures[0])\n","# pool = Pool(10)\n","# testData = pool.map(get_input_feature, all_figures)\n","\n","testData = []\n","t1 = time.time()\n","for idx, i in enumerate(all_figures):\n","    a = get_input_feature(i)\n","    testData.append(a)\n","    if idx % 1000 == 0:\n","        t2 = time.time()\n","        print(idx)\n","        print(t2 - t1)\n","        t1 = time.time()\n","\n","\n","x_all_test = np.asarray(testData)\n","y_all_test = np.asarray(testLabels)\n","\n","# np.savez('google_image_feature.npz', x_all=x_all, y_all=y_all)\n","np.savez('/content/drive/My Drive/Thesis/daytime_analysis/google_image_feature_upsampling.npz', x_all=x_all, y_all=y_all, \n","         x_all_test=x_all_test, y_all_test=y_all_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"emlNPRMqVOiO","colab_type":"code","colab":{}},"source":["# npzfile = np.load('google_image_feature_upsampling.npz')\n","# print npzfile.files\n","# x_all = npzfile['x_all']\n","# y_all = npzfile['y_all']\n","\n","x_train = x_all\n","x_test = x_all_test\n","y_train = y_all\n","y_test = y_all_test\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0TaAMAkfVSDo","colab_type":"code","colab":{}},"source":["# the model configuration: \n","# https://github.com/nealjean/predicting-poverty/blob/master/model/predicting_poverty_deploy.prototxt\n","model = Sequential()\n","model.add(Convolution2D(4096, 6, 6, activation='relu', input_shape=(12, 12, 512), subsample=(6, 6), name='input'))\n","model.add(Dropout(0.5))\n","model.add(Convolution2D(4096, 1, 1, activation='relu', subsample=(1, 1), name='conv_7'))\n","model.add(Dropout(0.5))\n","model.add(Convolution2D(4096, 1, 1, subsample=(1, 1), name='conv_8'))\n","model.add(AveragePooling2D((2, 2), strides=(1, 1), name='add_pool'))\n","\n","model.add(Flatten(name='flatten'))\n","model.add(Dense(3))\n","model.add(Activation(\"softmax\"))\n","\n","opt = SGD(lr=1e-2)\n","# model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n","model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n","\n","\n","model.fit(x_train, y_train, batch_size=100, nb_epoch=10, verbose=1)\n","\n","score = model.evaluate(x_test, y_test, verbose=0)  # 0.778 after 4 epoch\n","print(score)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETok9ycEVVjB","colab_type":"code","colab":{}},"source":["# get features\n","npzfile = np.load('/content/drive/My Drive/Thesis/nightlight.npz')\n","print npzfile.files\n","top_left_x_coords = npzfile['top_left_x_coords']\n","top_left_y_coords = npzfile['top_left_y_coords']\n","bands_data = npzfile['bands_data']\n","\n","\n","def get_cell_idx(lon, lat, top_left_x_coords, top_left_y_coords):\n","    lon_idx = np.where(top_left_x_coords < lon)[0][-1]\n","    lat_idx = np.where(top_left_y_coords > lat)[0][-1]\n","    return lon_idx, lat_idx\n","\n","\n","model_select = Model(input=model.input, output=model.get_layer('add_pool').output)\n","\n","\n","images_name = {} \n","for i in range(64):\n","    if i == 0: \n","        dir_ = '/content/google_images/google_images/' + str(i) + '/'\n","    else:\n","        dir_ = '/content/google_images/google_images/' + str(i+3) + '/'\n","    image_files = os.listdir(dir_)\n","    for f in image_files:\n","        images_name[f] = i\n","\n","\n","def get_input_feature_2(img_path):\n","    # img = image.load_img(img_path, target_size=(400, 400))\n","    img = image.load_img(img_path)\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    features = model_old.predict(x)\n","    pool_features = model_select.predict(features)\n","    return pool_features[0]\n","\n","def get_daytime_feature(sample):\n","    idx, wealth, x, y = sample\n","    print idx\n","    lon_idx, lat_idx = get_cell_idx(x, y, top_left_x_coords, top_left_y_coords)\n","    left_idx = lon_idx - 5\n","    right_idx = lon_idx + 4\n","    up_idx = lat_idx - 5\n","    low_idx = lat_idx + 4\n","    features_100 = []\n","    for i in xrange(left_idx, right_idx + 1):\n","        for j in xrange(up_idx, low_idx + 1):\n","            file_name = str(i) + '_' + str(j) + '.jpg'\n","            if file_name in images_name:\n","                luminosity = images_name[file_name]\n","                feature = get_input_feature_2('/content/google_images/google_images/' + str(luminosity) + '/' + file_name)\n","                features_100.append(feature)\n","    if len(features_100) == 0:\n","        print('nononono: ' + str(idx))\n","        return np.asarray([np.nan] * 4096 + [wealth]).tolist()\n","    else:\n","        features_100 = np.asarray(features_100)\n","        return np.append(np.mean(features_100, axis=0), wealth).tolist()\n","\n","\n","clusters = pd.read_csv('/content/drive/My Drive/Thesis/DHS_Data/bangladesh_cluster_avg_asset_2013_updated_new.csv')\n","clusters['feature'] = clusters.apply(lambda x: get_daytime_feature([x['cluster'], x['wlthindf'], \n","                                                                    x['longitude'], x['latitude']]), axis=1)\n","\n","data_all = clusters['feature']\n","data_all = np.asarray([i for i in data_all])\n","data_all = data_all[~np.isnan(data_all).any(axis=1)]\n","\n","np.savetxt('/content/drive/My Drive/Thesis/daytime_analysis/google_image_features_cnn_retrain.csv', data_all)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYEraoLTVk2n","colab_type":"code","colab":{}},"source":["data_all = np.loadtxt('/content/drive/My Drive/Thesis/daytime_analysis/google_image_features_cnn_retrain.csv')\n","\n","alphas_list = np.logspace(-1, 5, 7)\n","\n","final = []\n","for alpha in alphas_list:\n","    kf = KFold(n_splits=10, shuffle=True)\n","    scores = []\n","    for train_index, test_index in kf.split(data_all):\n","        reg = Ridge(alpha=alpha)\n","        train = data_all[train_index]\n","        test = data_all[test_index]\n","        train_x = train[:, :-1]\n","        train_y = train[:, -1]\n","        test_x = test[:, :-1]\n","        test_y = test[:, -1]\n","        # reduce dimensions to avoid overfitting\n","        pca = PCA(n_components=100)\n","        pca.fit(train_x)\n","        train_x = pca.transform(train_x)\n","        test_x = pca.transform(test_x)\n","        reg.fit(train_x, train_y)\n","        s = reg.score(test_x, test_y)\n","        scores.append(s)\n","    final.append(np.mean(scores))\n","\n","print 'R^2 of the best model: {:.3f}'.format(np.max(final))\n"],"execution_count":0,"outputs":[]}]}